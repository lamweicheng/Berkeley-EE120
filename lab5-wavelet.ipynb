{"cells":[{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"# Initialize Otter\nimport otter\ngrader = otter.Notebook(\"lab5-wavelet.ipynb\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EE 120 Lab 5: Wavelets\n\n**Signals and Systems** at UC Berkeley\n\nAcknowledgements:\n\n- **Spring 2020** (v1.0): Ilya Chugunov, Babak Ayazifar  \n- **Fall 2020** (v1.1): Anmol Parande, Naomi Sagan\n- **Spring 2022** (v2.0): Naomi Sagan"},{"metadata":{"trusted":false},"cell_type":"code","source":"from utils.array2gif import write_gif\nfrom utils.test import test_haar_dec, test_haar_rec\nfrom IPython.display import Image\nimport time\nimport copy\nimport numpy as np\nimport scipy.signal\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Background: Wave·let /ˈwāvlit/\n\nGoogle suggests the definition of a wavelet to be: \"a small wave of water; a ripple.\" Surprisingly, in the signal processing context, this definition isn't too far from the point. \n\nSo far, all of our frequency domain building blocks — our complex exponentials $e^{i \\omega t}$ — correspond to infinite-duration signals in time: they oscillate on and on forever. So, whenever we apply the CTFT or DTFT to a *finite-duration* signal, expressing it as a linear combination of these *infinite-duration* complex exponentials, we need an infinite number of these building blocks to cancel each other out anywhere outside the signal's [region of support](https://en.wikipedia.org/wiki/Support_(mathematics)). \n\nThis issue led to the introduction of the Discrete Fourier Transform (DFT), specially designed for finite-duration signals, but introduced a new problem: many discrete-time signals have an **inefficient representation** in the DFT. That is, the signals require an incommensurately large number of nonzero DFT coefficients to encode, given their simple time-domain behavior. In more technical terms, we say that finite duration signals are not **sparse** in the Fourier domain.\n\nAs a prototypical example, let's consider a 256-point signal $x(n)$ defined as:\n\n$$x(n) = \\begin{cases}\n    2, & \\text{for } 0 \\leq n < 128 \\\\\n    1, & \\text{for } 128 \\leq n < 192 \\\\\n    0, & \\text{for } 192 \\leq n < 256\n  \\end{cases}$$ \n  \nand zero elsewhere. This is just a sum of two 128-point [rectangular](https://en.wikipedia.org/wiki/Rectangular_function) signals. \n\nLet's plot $x$ as well as the magnitude of its DFT coefficients. We'll also verify that taking the inverse DFT perfectly reconstructs the signal."},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.concatenate((np.ones(128) * 2, np.ones(64), np.zeros(64)))\nX = np.fft.fftshift(np.fft.fft(x))\nx_ifft = np.fft.ifft(np.fft.fftshift(X))\n\nfig, axs = plt.subplots(1, 3, figsize=(18,6))\naxs[0].plot(x)\naxs[0].set_title(\"x(n)\")\naxs[0].set_ylim(-0.1,2.1)\naxs[0].set_xlabel(\"Time (samples)\")\naxs[1].plot(np.linspace(-np.pi, np.pi, X.size), np.abs(X))\naxs[1].set_title(\"|X($\\omega$)|\")\naxs[1].set_xlabel(\"Frequency (radians)\")\naxs[2].plot(np.abs(x_ifft))\naxs[2].set_title(\"Inverse DTFT of X($\\omega$)\")\naxs[2].set_ylim(-0.1,2.1)\naxs[2].set_xlabel(\"Time (samples)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ignoring the differences in space required for encoding data types for now (e.g., the number of bytes used to encode a `float64` versus a `complex128`), we find that just as $x$ takes 256 coefficients to encode in the time domain, it also takes 256 DFT coefficients to encode. If we keep all 256 DFT coefficients, we can recover $x$ in the time-domain with the inverse DFT. So far, nothing new or surprising.\n\nHow important are the various DFT coefficients though? What if we throw away some coefficients? Let's see what happens if we zero out every other coefficient, effectively downsampling the DFT by 2."},{"metadata":{"trusted":false},"cell_type":"code","source":"X = np.fft.fftshift(np.fft.fft(x))\nX[1::2] = 0 # zero every other coefficient\nx_ifft = np.fft.ifft(np.fft.fftshift(X))\n\nfig, axs = plt.subplots(1, 3, figsize=(18,6))\naxs[0].plot(x)\naxs[0].set_title(\"x(n)\")\naxs[0].set_ylim(-0.1,2.1)\naxs[0].set_xlabel(\"Time (samples)\")\naxs[1].plot(np.linspace(-np.pi, np.pi, X.size), np.abs(X))\naxs[1].set_title(\"|X($\\omega$)|\")\naxs[1].set_xlabel(\"Frequency (radians)\")\naxs[2].plot(np.abs(x_ifft))\naxs[2].set_title(\"Inverse DTFT of X($\\omega$)\")\naxs[2].set_ylim(-0.1,2.1)\naxs[2].set_xlabel(\"Time (samples)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though we only have to store half the coefficients, we in exchange don't exactly reconstruct the original signal, rather getting a scaled and aliased copy (if you throw away every other DFT sample, you have essentially reduced the sampling frequency of the signal). This should tell you that these coefficients are significant even though they are small.\n\nSince throwing out half the DFT coefficients didn't work too well, let's take a slightly more principled approach. Knowing that $x$ is piecewise-constant, we expect the low frequency compnents to describe the general trend of the signal whereas the high frequency components will capture the discontinuities; what would happen if we were to discard just the half of the coefficients corresponding to the high-frequency components?"},{"metadata":{"trusted":false},"cell_type":"code","source":"X = np.fft.fftshift(np.fft.fft(x))\nX[:64] = 0  # zero out DTFT from -pi to -pi/2\nX[192:] = 0 # zero out DTFT from pi/2 to pi\nx_ifft = np.fft.ifft(np.fft.fftshift(X))\n\nfig, axs = plt.subplots(1, 3, figsize=(18,6))\naxs[0].plot(x)\naxs[0].set_title(\"x(n)\")\naxs[0].set_xlabel(\"Time (samples)\")\naxs[1].plot(np.linspace(-np.pi, np.pi, X.size), np.abs(X))\naxs[1].set_title(\"|X($\\omega$)|\")\naxs[1].set_xlabel(\"Frequency (radians)\")\naxs[2].plot(np.abs(x_ifft))\naxs[2].set_title(\"Inverse DTFT of X($\\omega$)\")\naxs[2].set_xlabel(\"Time (samples)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, we throw out half the coefficients, and our reconstruction of $x$ suffers as a result, with an obvious [Gibbs artifact](https://en.wikipedia.org/wiki/Gibbs_phenomenon) in the result. This happens because those high frequency components of the DFT that we discarded were responsible for preserving the fast changes in signal (edges) at $n = 128$ and $n=192$. \n\nThis is what we mean when we say $x$ has an *inefficient representation* in the DFT basis: $x$ is very simple to describe in the time domain (there's only two places where it does anything interesting — its edges), but in the frequency domain every coefficient plays an essential role in its reconstruction, meaning we have to keep all 256 pesky coefficients in computer memory.\n\nThis leads us to a new idea: we know $x$ is just constructed from rectangles, so what if we tried using a basis of rectangles to represent it?"},{"metadata":{},"cell_type":"markdown","source":"# Q1: The Haar Wavelet: a basis made of rectangles and not useless smooth sinusoids."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"figs/curves.svg\" alt=\"drawing\" style=\"width:60%;\"/>"},{"metadata":{},"cell_type":"markdown","source":"The \"basis of rectangles\" we described before is known as the **Haar Basis** (a.k.a the Haar Wavelet). Before we dissect it further, it's worth emphasizing that the main lessons of this lab aren't in the details of wavelets that are emphasized in later courses like EE 123 and 225B (in particular, the theory behind [mother wavelets](https://en.wikipedia.org/wiki/Wavelet#Mother_wavelet) and [time-frequency tradeoffs](https://en.wikipedia.org/wiki/Time%E2%80%93frequency_representation)), but rather on the philosophy behind their existence: **generalization**.\n\nThe DFT analysis equation \n\n$$ X[k] =\\sum_{n=0}^{N-1} x(n) \\cdot \\underbrace{e^{-\\frac{i 2 \\pi}{N} k n}}_{\\phi_k^*(n)} = \\langle x, \\phi_k \\rangle $$\n\ntells us that we can compute DFT coefficients by projecting our signal onto the basis $\\{\\phi_0, ..., \\phi_{N-1}\\}$, where $\\phi_k(n) = e^{i \\frac{2\\pi}{N} kn}$. But is this complex exponential somehow special, such that replacing the $\\phi$'s with another basis is impossible? Does it form a basis better than any other?\n\nWell no, not really.  \n\nComplex exponentials are convenient: they're easy to manipulate mathematically, and many real-life signals can be efficiently represented by using them as a basis. However, there are also many classes of signals, such as the one we saw in the previous part of the lab, that aren't efficiently expressible as a linear combination by complex exponentials. For this reason, back in the 1980s and 1990s, mathematicians, physicists, and engineers alike were racing to use the coolest wavelet bases they could for applications from computer vision to quantum field theory [1]. And there were quite a few to choose from: we had [Mathieu](https://en.wikipedia.org/wiki/Mathieu_wavelet), [Legendre](https://en.wikipedia.org/wiki/Legendre_wavelet), and [Daubachies](https://en.wikipedia.org/wiki/Daubechies_wavelet) wavelets, or if that wasn't enough last names for you, you could use a [Cohen–Daubechies–Feauveau](https://en.wikipedia.org/wiki/Cohen%E2%80%93Daubechies%E2%80%93Feauveau_wavelet) wavelet! There were even such questionably named wavelets as the [Mexican Hat](https://en.wikipedia.org/wiki/Mexican_hat_wavelet) and its cousin the [Complex Mexican Hat](https://en.wikipedia.org/wiki/Complex_Mexican_hat_wavelet).\n\nWith these new bases we also have a new synthesis equation for the discrete time wavelet transform (DWT),\n\n$$x(n)= \\left( \\sum_{s} \\sum_{u} d_{s, u} \\cdot \\Psi_{s, u}(n) \\right) + \\alpha \\cdot \\Phi(n), \\qquad(1)$$\n\nwhere\n\n$$ d_{s, u} = \\langle x , \\Psi_{s, u} \\rangle \\quad \\quad \\text{and} \\quad \\quad \\alpha = \\langle x, \\Phi \\rangle .$$"},{"metadata":{},"cell_type":"markdown","source":"Now, our signal $x$ is a weighted sum of scaled and shifted *mother wavelets* $\\Psi_{s, u}$, and one *father wavelet* $\\Phi$. For now, it's fine to think of these as some arbitrary orthonormal bases.\n\nThe weighting coefficients, $d_{s,u}$ and $a$, are found by taking the inner product of our signal vector and basis vectors. Just as with the DFT, they represent how well the signal \"matches\" or correlates with that particular *atom* (i.e., basis vector, or *wavelet*). \n\nIn the case of the Haar basis, our wavelets look like this:\n\n<img src=\"figs/haar_scales.svg\" alt=\"drawing\" style=\"width:80%;\"/>"},{"metadata":{},"cell_type":"markdown","source":"Notice that the father wavelet is the \"lowest\" frequency while the mother wavelet represents \"higher frequencies\". Our basis is essentially formed by scaling and shifting the mother wavelet. \n\nLet's start out by creating the first 4 Haar wavelets, which we'll call `phi`, `psi_0_0`, `psi_1_0`, and `psi_1_1`.\n\nThese wavelets should:\n   1. Be length 256 vectors;\n   2. Follow the shape of the figure above (symmetric about a particular point on the x-axis); and\n   3. Have a euclidean norm (square root of the inner product of the signal with itself) of 1.\n\nThe **un-normalized** versions of these vectors are:\n$$\\Phi = \\begin{bmatrix} 1 & \\cdots & 1 \\end{bmatrix}$$\n$$\\Psi_{0, 0}(n) = \\begin{cases}\n    1, & 0 \\leq n < 128 \\\\\n    -1, & 128 \\leq n < 256\n\\end{cases}$$\n$$\\Psi_{1, 0}(n) = \\begin{cases}\n    1, & 0 \\leq n < 64 \\\\\n    -1, & 64 \\leq n < 128 \\\\\n    0, & 128 \\leq n < 256\n\\end{cases}$$\n$$\\Psi_{1, 1}(n) = \\begin{cases}\n    0, & 0 \\leq n < 128 \\\\\n    1, & 128 \\leq n < 192 \\\\\n    -1, & 192 \\leq n < 256\n\\end{cases}$$\nYou will have to normalize each vector to have norm 1. `np.linalg.norm` might be useful here.\n\n##### Side Note: if the assumptions we make in this lab are unsatisfactory to you, it's because we leave the rigorous mathematics for EE 123, which takes deep dive into this territory of signal analysis and much much more!"},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"phi = ...\n\npsi_0_0 = ...\n\npsi_1_0 = ...\n\npsi_1_1 = ...","execution_count":null,"outputs":[]},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check(\"q1a\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot these wavelets to see if they look correct."},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize=(18,6))\naxs[0].plot(phi)\naxs[0].set_title(\"$\\Phi(n)$\")\naxs[1].set_xlim(-10, 267)\naxs[1].plot(psi_0_0)\naxs[1].set_title(\"$\\Psi_{0,0}(n)$\")\naxs[2].plot(psi_1_0)\naxs[2].set_title(\"$\\Psi_{1,0}(n)$\")\naxs[3].plot(psi_1_1)\naxs[3].set_title(\"$\\Psi_{1,1}(n)$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q:** Based on the plots above, do you expect this basis to be orthonormal? Why?"},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n<!-- BEGIN QUESTION -->\n\nNow, let's check the orthonormality of this basis by looking at their pair-wise inner products:"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"<phi     , phi>     = \", np.dot(phi, phi).round(3))\nprint(\"<psi_0_0 , psi_0_0> = \", np.dot(psi_0_0, psi_0_0).round(3))\nprint(\"<psi_1_0 , psi_1_0> = \", np.dot(psi_1_0, psi_1_0).round(3))\nprint(\"<psi_1_1 , psi_1_1> = \", np.dot(psi_1_1, psi_1_1).round(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"<phi     , psi_0_0> = \", np.dot(phi, psi_0_0).round(3))\nprint(\"<psi_0_0 , psi_1_0> = \", np.dot(psi_0_0, psi_1_0).round(3))\nprint(\"<psi_1_0 , psi_1_1> = \", np.dot(psi_1_0, psi_1_1).round(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q:** Do the inner products confirm your suspicion about the orthonormality of the wavelets?"},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\nNext, calculate coefficients `a`, `d_0_0`, `d_1_0`, `d_1_1` as in Eq 1. above for our original signal x by taking the dot product of $x$ with each wavelet."},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.concatenate((np.ones(128)*2, np.ones(64), np.zeros(64))) # as a reminder","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"a = ...\nd_0_0 = ...\nd_1_0 = ...\nd_1_1 = ...\nprint(\"a = \", a, \", d_0_0 = \", d_0_0, \", d_1_0 = \", d_1_0, \", d_1_1 = \", d_1_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create and plot a reconstructed `x_hat` via the synthesis equation in Eq. 1 (you can just sum the products manually for now, no need for a `for` loop).  \nIf everything went correctly, the original signal `x` and `x_hat` should look identical."},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"x_hat = ...","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(12,5))\naxs[0].plot(x)\naxs[0].set_title(\"$x(n)$\")\naxs[1].plot(x_hat)\naxs[1].set_title(\"$\\hat{x}(n)$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check(\"q1d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Incredible! We can reconstruct the time-domain $x$ perfectly with just 4 wavelet coefficients! That's 64 times less memory than we had to store for the DTFT coefficients with no loss in signal information.\n\nBut what have we learned about the signal itself? Does this Haar wavelet transform tell us any information like the DTFT? Yes, and more!\n\nLet's zoom in on our *level 1 wavelets*. The level is equivalent to $s$, the first index of our wavelets, and represents the \"scale\" of the wavelet in time.\n \n We can see that both $\\Psi_{1,0}$ and $\\Psi_{1,1}$, shown below\n\n<img src=\"figs/level1.svg\" alt=\"drawing\" style=\"width:48%;\"/>\n\nare finite-duration signals. In particular, $\\Psi_{1,0}$ is only nonzero for the left side of the vector, and $\\Psi_{1,1}$ is nonzero for the right side.\n\nIf we look at the higher level wavelets, we see they get thinner and thinner (i.e they are scaled in time more and more):\n\n<img src=\"figs/scales.svg\" alt=\"drawing\" style=\"width:55%;\"/>\n\nIn other words, wavelets encode both frequency information (as $s$ increases, the wavelet becomes thinner, detecting higher frequency changes in the signal) and temporal information (as $u$ changes you sample different parts of $x(n)$). Here's a way to visualize this phenomenon, comparing the Fourier basis with the Haar basis:\n\n<img src=\"figs/time_frequency_blocks.svg\" alt=\"drawing\" style=\"width:40%;\"/>\n\nEach complex exponential from the DTFT corresponds to an infinitely long signal ($e^{i \\omega n}$ doesn't decay for large n) but at one specific frequency, whereas a wavelet can correspond to both a range of frequencies (depending on its shape) and a range of time (depending on its support in time). The size of these boxes in time-frequency space is limited by the [uncertainty principle](https://en.wikipedia.org/wiki/Uncertainty_principle#Harmonic_analysis), the same one you might have heard of from quantum physics.\n\nWith that in mind, as well as the wavelet coefficients you computed (reproduced below), answer the following questions."},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"a = \", a, \", d_0_0 = \", d_0_0, \", d_1_0 = \", d_1_0, \", d_1_1 = \", d_1_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q:** What do you notice about the coefficient `d_1_0`? What does this say about the signal behaviour in the left half of $x(n)$?"},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n**Q:** Which is larger, `d_0_0` or `d_1_0`? Does this mean $x(n)$ is a predominantly low-frequency or high-frequency signal?"},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n# Q2: Where do you store wavelets? In a filter bank."},{"metadata":{},"cell_type":"markdown","source":"Though we've gained some intuition about the Haar wavelet and its coefficients, manually calculating them is quite tedious. We stopped at the first level wavelets and coefficients, but in general, a signal of length $N$ would require $\\log_2(N)$ wavelet levels, each with $2^u$ coefficients to calculate. This would be an absolute computational nightmare to do by hand if we had to manually calculate all the dot products.\n\nLuckily, the Haar basis is quite convenient. For both signal decomposition (i.e., analysis) and reconstruction (i.e., synthesis), the process can be implemented via a [*filter bank*](https://en.wikipedia.org/wiki/Filter_bank): a recursively structured set of down or upsampled convolutions."},{"metadata":{},"cell_type":"markdown","source":"## Haar Analysis\n\nHere's the block diagram for our Haar decomposition filter bank (a.k.a applying the \"analysis equation\"):\n\n<img src=\"figs/haardec.svg\" alt=\"drawing\" style=\"width:70%;\"/>\n\nWe see that each step of the process involves first passing the signal $x$ through $g$, a low-pass filter, and $h$, a high-pass filter, before down-sampling the produced signals by a factor of two. Rather than operating with various scales of $\\Psi_{s,u}$, horizontally compressing our basis functions, we're instead scaling the signal $x$ itself, allowing us to keep the same simple set of filters $g$ and $h$ through the whole process."},{"metadata":{},"cell_type":"markdown","source":"## Haar Synthesis\n\nSimilarly, this is the block diagram for Haar reconstruction (aka, applying the \"synthesis equation\"):\n\n<img src=\"figs/haarrec.svg\" alt=\"drawing\" style=\"width:70%;\"/>\n\nAs you can see, this follows the same principles as decomposition but in reverse. The filters $\\hat{g}$ and $\\hat{h}$ are time-reversed versions $g$ and $h$, and the downsampling operator is replaced with upsampling (in this case an [expander](https://en.wikipedia.org/wiki/Upsampling), inserting zeroes between signal elements).\n\nNote that for both decomposition and reconstruction, the coefficient outputs are now arrays, meaning that to recover `d_s_u` you'd need to look at the $u$-th element of the $s$-th coefficient array.\n\n**Q:** Implement the `haar_dec` and `haar_rec` functions as outlined in the block diagrams above. We've given you an upsampler helper function and test code for convenience. Make sure you use \"same\" mode for convolution since want to keep all vectors the same length (besides the downsampling/upsampling).\n\n**You may want to use the following functions:**  \n    [np.convolve](https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html), [list.insert()](https://www.programiz.com/python-programming/methods/list/insert), and [list.pop()](https://www.programiz.com/python-programming/methods/list/pop)"},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"def haar_dec(signal):\n    g = np.array([1,1])/np.sqrt(2) \n    h = np.array([1,-1])/np.sqrt(2)\n    \n    coefficients = []\n    \n    ### TODO: YOUR CODE HERE\n    ...\n    return coefficients\n\ndef upsample_2(coefficients):\n    if len(coefficients) == 1:\n        return [coefficients[0], 0]\n    \n    out = np.zeros(2 * len(coefficients))\n    out[::2] = coefficients\n    return out\n\ndef haar_rec(coefficients):\n    coefficients = copy.deepcopy(coefficients)\n    g_hat = np.array([1,1])/np.sqrt(2) \n    h_hat = np.array([-1,1])/np.sqrt(2)\n    \n    signal = 0\n    \n    ### TODO: YOUR CODE HERE\n    ...\n    return signal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the tests below to check the validity of your code:"},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check(\"q2a\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also check that `haar_rec` of the `haar_dec` of a signal returns the same signal.  \nCompare $x$ and $\\hat{x}$ below and verify that they look identical."},{"metadata":{"trusted":false},"cell_type":"code","source":"x_hat = haar_rec(haar_dec(x))\n\nfig, axs = plt.subplots(1, 2, figsize=(12,5))\naxs[0].plot(x)\naxs[0].set_title(\"$x(n)$\")\naxs[1].plot(x_hat)\naxs[1].set_title(\"$\\hat{x}(n)$\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The simplicity and recursive nature of this Haar decomposition and reconstruction process, combined with taking advantage of vectorized operation in NumPy, allows this code to run blazingly fast.  \n\n\nFor an arbitrary $2^{20} = 1048576$-point signal, the code should take only a fraction of a second to run:"},{"metadata":{"trusted":false},"cell_type":"code","source":"long_test = np.random.randn(1048576)\nstart = time.time()\nlong_test = haar_dec(long_test)\nprint(\"Decomposition took {0} seconds.\".format(time.time()-start))\nstart = time.time()\nlong_test = haar_rec(long_test)\nprint(\"Reconstruction took {0} seconds.\".format(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n**Q:** What in this implementation of Haar decomposition allows it to run faster (i.e., perform less operations) than finding coefficients directly via dot products as we were doing earlier? "},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n# Q3: Applications\n\nHaving developed some basic intuition for wavelets and how they generalize the DFT, we'll now explore some of their applications."},{"metadata":{},"cell_type":"markdown","source":"## Q3a: Compression\n\nAs mentioned before, wavelets have applications in fields from MRI to quantum physics, but for now we'll focus our attention on image processing.\n\nFor the purposes of this lab, we'll treat images as just folded-up one-dimensional signals to simplify things, but there are the two-dimensional (and more generally, N-dimensional) [discrete wavelet transform](https://en.wikipedia.org/wiki/Discrete_wavelet_transform) that we should be using for higher dimensional data.\n\nLet's load an image and take its Haar decomposition (notice we flatten the image first):"},{"metadata":{"trusted":false},"cell_type":"code","source":"blocks = plt.imread('data/blocks.tif') # load image from file","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.imshow(blocks, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"blocks_dec = haar_dec(blocks.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"blocks_rec = haar_rec(blocks_dec).reshape(512,512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.imshow(blocks_rec, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just as in the 1D case, we're able to successfully decompose and reconstruct our blocky image. Here we use [np.flatten()](https://numpy.org/doc/1.18/reference/generated/numpy.ndarray.flatten.html) to collapse a multidimensional array into a 1D array, and [np.reshape()](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) to convert this 1D array back into 2D.  \n\nThese functions might be useful later."},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n**Q:** Why might Haar be a good basis to represent this image? How is this image similar to the signal $x$ we used in the 1D parts of the lab?"},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n**Q:** Use the code block below to help answer this:  \n1. What coefficient levels have non-zero coefficients? \n2. How many coefficients would we have to keep if we only kept levels that had non-zero coefficients? \n3. What percent of the total coefficients is that?"},{"metadata":{"trusted":false},"cell_type":"code","source":"blocks_dec = haar_dec(blocks.flatten()) # wavelet decomposition of the blocks image\n\ntotal_coeffs = 0\nfor i, level in enumerate(blocks_dec):\n    print(\"level {0} mean:\".format(i), np.mean(np.abs(level)))\n    total_coeffs += len(level)\nprint()\nnon_zero_coeffs = len(blocks_dec[0]) + len(blocks_dec[1]) + len(blocks_dec[10]) + len(blocks_dec[11]) + len(blocks_dec[12])\nprint(\"Total nonzero coefficients: \", non_zero_coeffs)\nprint()\nprint(\"We only need to keep {0}% of the coefficients to fully reconstruct the image\".format(non_zero_coeffs/total_coeffs *100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\nWe see that we only need to keep a fraction of the Haar coefficients, or equivalently a fraction of the image data, to reconstruct the whole image. However, **having few non-zero coefficients does not mean that data is easily compressible!** It's the combination of both having few non-zero coefficients, and knowing exactly **where** those non-zero coefficients are that makes data compressible.\n\n<img src=\"figs/compressible_blocks.svg\" alt=\"drawing\" style=\"width:35%;\"/>\n\nIn the above example, imagine the white blocks in the 4x4 matrices are non-zero elements and the black blocks are zero.  \nTo send the first matrix all we need to do is send its size (4,4) and the first four elements (assuming we build our matrices top-down). On the receiving end, we then assume that whatever we didn't receive is zero. In other words, if we receive the signal $[(4, 4), a, b, c, d]$ this constructs the matrix $\\left[\\begin{array}{cccc}\na & b & c & d\t\\\\\n0 & 0 & 0 & 0\t\\\\\n0 & 0 & 0 & 0\t\\\\\n0 & 0 & 0 & 0\n\\end{array}\\right]$, so 6 coefficients to construct a 4x4 matrix.  \n\nIn the case of the second \"not easily compressible\" matrix, with this scheme we have to either send the matrix size and all elements until the last non-zero element (the first 13 elements), or send each non-zero element with an (x,y) position attached:\n\n$[(4, 4), (a, 1, 3), (b, 3, 2), (c, 2, 1), (d, 0, 0)] \\rightarrow \\left[\\begin{array}{cccc}\n0 & a & 0 & 0\t\\\\\n0 & 0 & 0 & b\t\\\\\n0 & 0 & c & 0\t\\\\\nd & 0 & 0 & 0\n\\end{array}\\right]$\n\nFor a total of 14 coefficients to construct a 4x4 matrix.\n\nThus it's easy to see why the Haar decomposition above is truly compressible, instead of sending levels with zero coefficients, we can send an empty array [None]. We don't even need to store the sizes of these level arrays, during reconstruction we can always back-calculate them, knowing that each level must have twice the coefficients of the previous."},{"metadata":{},"cell_type":"markdown","source":"## Q3b: Wavelet Denoising"},{"metadata":{},"cell_type":"markdown","source":"Suppose our blocky image from the previous section encountered some signal noise during transmission and now looks like this:"},{"metadata":{"trusted":false},"cell_type":"code","source":"noisy_blocks = plt.imread('data/blocks_noisy.tif')\n\nplt.figure(figsize=(8,8))\nplt.imshow(noisy_blocks, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the ways we might think to remove this noise is just to smooth the image, averaging the specks of noise into oblivion:"},{"metadata":{"trusted":false},"cell_type":"code","source":"# smooth image with averaging filter:\ncleaner_blocks = scipy.signal.convolve2d(noisy_blocks, np.ones((20,20)), mode=\"same\")\n\nplt.figure(figsize=(8,8))\nplt.imshow(cleaner_blocks, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although this works, we've lost the crisp edges we had before, so this might have actually made our image quality worse overall...\n\nWell we know that our Haar basis constructs nice crisp edges, maybe looking at the decomposition can help us?"},{"metadata":{"trusted":false},"cell_type":"code","source":"noisy_blocks_dec = haar_dec(noisy_blocks.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" for i, level in enumerate(noisy_blocks_dec):\n        print(\"level {0} mean:\".format(i), np.mean(np.abs(level)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting, while the largest average coefficients seem to be in the same levels as for the clean block image, our decomposition has now been by a swarm of tiny coefficients brought on by noise.\n\nIf in the Haar decomposition, the noise coefficients are significantly smaller than the real signal coefficients, maybe we can just threshold them out?\n\n**Q:** Fill out the helper function below to set all elements in the `coefficients` array whose **MAGNITUDE** (not value) is less than `threshold` to zero:"},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"def threshold_coefficients(coefficients, threshold):\n    coefficients = copy.deepcopy(coefficients)\n    \n    ### TODO: YOUR CODE HERE\n    ...\n    return coefficients","execution_count":null,"outputs":[]},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check(\"q3b\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Play with the threshold value below until the small coefficients are successfully thresholded, i.e. the means for all levels except those with real signal are zero.  \nIf all the means are zero, the threshold is probably too high, if none are zero, it's probably too low.  "},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n"},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"threshold = ...\ndenoised_dec = threshold_coefficients(noisy_blocks_dec, threshold)\nfor i, level in enumerate(denoised_dec):\n    print(\"level {0} mean:\".format(i), np.mean(np.abs(level)))\n    \nplt.figure(figsize=(8,8))\nplt.imshow(haar_rec(denoised_dec).reshape(512,512), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\nIf you picked a good threshold, the image above should be successfully denoised!  \nThe block edges should be preserved and there should be little to no noise left.  \n  \n  \nThe take-away lesson here is that wavelets can be a powerful tool for separating noise from signal. If the signal is compressible in the wavelet basis (few large non-zero coefficients) and the noise is not compressible (many small non-zero coefficients), it's easy to just threshold the noise out."},{"metadata":{},"cell_type":"markdown","source":"## Q3c: Wavelet Deblurring\n\nJust how sparse noise doesn't cleanly fit into our Haar decomposition model and can be thresholded out, so too does blurring (after all, the Haar bases are sharp and jagged, the antithesis of a smooth blur function).\n\nThus we can eliminate blurring with the same process as the previous example:"},{"metadata":{"trusted":false},"cell_type":"code","source":"blurred_blocks = plt.imread('data/blocks_blurry.tif')\nplt.figure(figsize=(8,8))\nplt.imshow(blurred_blocks, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"blurred_dec = haar_dec(blurred_blocks.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"threshold = 300\ndeblurred_dec = threshold_coefficients(blurred_dec, threshold)\nfor i, level in enumerate(deblurred_dec):\n    print(\"level {0} mean:\".format(i), np.mean(np.abs(level)))\n    \nplt.figure(figsize=(8,8))\nplt.imshow(haar_rec(deblurred_dec).reshape(512,512), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q:** You can try changing the `threshold` value above, but it seems no matter what we pick, we cant get rid of the up-down blur, why is this? (You might need to read up on [np.flatten()](https://www.w3resource.com/numpy/manipulation/ndarray-flatten.php) to answer this.)"},{"metadata":{},"cell_type":"markdown","source":"<!-- BEGIN QUESTION -->\n\n<span style=\"color:blue\">**A:** (TODO - Double click this cell and write your answer)"},{"metadata":{},"cell_type":"markdown","source":"<!-- END QUESTION -->\n\n**Q:** Based off this realization, devise a way to deblur both the rows and columns of the image. You may want to start with the result of the previous code:"},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"almost_deblurred_image = haar_rec(deblurred_dec).reshape(512,512)\ndeblurred_image = None\n\n### TODO: YOUR CODE HERE\n...","execution_count":null,"outputs":[]},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check(\"q3c2\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.imshow(deblurred_image, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result should be a perfectly deblurred image!"},{"metadata":{},"cell_type":"markdown","source":"# Q4: Wavelet $\\leftrightarrow$ Rowlet (Bonus Example)"},{"metadata":{},"cell_type":"markdown","source":"This is a bonus animation showing why a video stream you're watching might look blocky at times.\n\nLet's look at a lovely bouncing Rowlet [2], a Grass/Flying Pokémon (**warning**: `write_gif` might take a bit of time to run):"},{"metadata":{"trusted":false},"cell_type":"code","source":"rowlet = np.load(\"data/rowlet.npy\") # load data\nrowlet_shape = rowlet.shape # extract shape\n\nwrite_gif(np.repeat(rowlet[:,:,:,None], 3, axis=3), \"data/rowlet.gif\", fps=20) # write to gif format\nImage(url=\"data/rowlet.gif\", width=256) # display","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rowlet_dec = haar_dec(rowlet.flatten())\nprint(\"Rowlet Haar decomposition has {0} levels.\".format(len(rowlet_dec)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at its Haar decomposition, we see that it has 22 levels, but say that we're streaming this video in real time, sending data from some server over the internet one packet at a time.\n\nThere's no real reason we have to send all 22 coefficient levels at once, we can send the first level coefficients (1 coefficients), then the second level coefficients (2 coefficients), then the third level coefficients (4 coefficients), and so forth. On the receiving end, your computer, we can also start reconstructing the video stream one coefficient level at a time, first building a very blocky image, then a sharper and sharper one as more high frequency coefficients arrive.\n\nThis is what that looks like:"},{"metadata":{"trusted":false},"cell_type":"code","source":"rowlets = []\nrowlets.append(rowlet)\n\nfor i in range(21, 14, -1):\n    rowlet_dec[i] = 0*rowlet_dec[i] # zero level coefficients\n    rowlet_blocky = haar_rec(rowlet_dec).reshape(rowlet_shape)\n    \n    # repeat for columns\n    rowlet_blocky = rowlet_blocky.swapaxes(1,2)\n    rowlet_blocky_dec = haar_dec(rowlet_blocky.flatten())\n    for j in range(21, i, -1):\n        rowlet_blocky_dec[j] = 0*rowlet_blocky_dec[j]\n        \n    rowlet_blocky = haar_rec(rowlet_blocky_dec).reshape(rowlet_shape).swapaxes(1,2)\n    # rescale array to range 0-255\n    rowlet_blocky = rowlet_blocky - np.min(rowlet_blocky)\n    rowlet_blocky = rowlet_blocky/np.max(rowlet_blocky)*255\n    rowlet_blocky = rowlet_blocky.astype(np.uint8)\n    \n    rowlets.insert(0, rowlet_blocky)\n    \nrowlets = np.concatenate(rowlets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"write_gif(np.repeat(rowlets[:,:,:,None], 3, axis=3), \"data/rowlet_blocky.gif\", fps=20) # takes a while to run\nImage(url=\"data/rowlet_blocky.gif\", width=256)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each loop of the animation represents the addition of one level of Haar coefficients.\n\nSince we're sending one level of coefficients at a time, if by the time your computer would get, say, level 15 coefficients it's also time to render the next frame of the animation, the computer will display whatever it's got at the moment, which may be a weird blocky video frame. Although Netflix or Hulu uses different compression algorithms than just Haar wavelets, this is the reason that when your internet is slow and unreliable, the video starts to look blocky; not all the coefficients are arriving in time!\n\nIf you are more curious about Wavelet Compression, you can read about one compression scheme called Embedded Zero-Trees of Wavelet Transforms <a href=\"https://medium.com/swlh/end-to-end-image-compression-using-embedded-zero-trees-of-wavelet-transforms-ezw-2362f2a965f7\">here</a>. "},{"metadata":{},"cell_type":"markdown","source":"## References:\n\n[1] Debnath, L. (1998). Brief historical introduction to wavelet transforms. International Journal of Mathematical Education in Science and Technology, 29(5), 677-688.  \n[2] Gif sourced from sodakick @ tumblr, url unknown."},{"metadata":{"deletable":false,"editable":false},"cell_type":"markdown","source":"---\n\nTo double-check your work, the cell below will rerun all of the autograder tests."},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.check_all()","execution_count":null,"outputs":[]},{"metadata":{"deletable":false,"editable":false},"cell_type":"markdown","source":"## Submission\n\nMake sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n\nPlease upload the zip file produced by the result of this command to Gradescope."},{"metadata":{"deletable":false,"editable":false,"trusted":false},"cell_type":"code","source":"grader.export(force_save=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" "}],"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.9.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"otter":{"tests":{"q1a":{"name":"q1a","points":10,"suites":[{"cases":[{"code":">>> assert np.isclose(np.linalg.norm(phi), 1)\n>>> assert np.isclose(np.linalg.norm(psi_0_0), 1)\n>>> assert np.isclose(np.linalg.norm(psi_1_0), 1)\n>>> assert np.isclose(np.linalg.norm(psi_1_1), 1)\n","hidden":false,"locked":false},{"code":">>> assert np.allclose(phi - 16**-1, np.zeros(256))\n>>> assert np.allclose(psi_0_0[:128] - 16**-1, np.zeros(128))\n>>> assert np.allclose(psi_0_0[128:] + 16**-1, np.zeros(128))\n>>> assert np.allclose(psi_1_0[:64] - np.sqrt(128)**-1, np.zeros(64))\n>>> assert np.allclose(psi_1_0[64:128] + np.sqrt(128)**-1, np.zeros(64))\n>>> assert np.allclose(psi_1_0[128:], np.zeros(128))\n>>> assert np.allclose(psi_1_1[:128], np.zeros(128))\n>>> assert np.allclose(psi_1_1[128:192] - np.sqrt(128)**-1, np.zeros(64))\n>>> assert np.allclose(psi_1_1[192:] + np.sqrt(128)**-1, np.zeros(64))\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q1d":{"name":"q1d","points":10,"suites":[{"cases":[{"code":">>> assert np.allclose(x, x_hat)\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q2a":{"name":"q2a","points":20,"suites":[{"cases":[{"code":">>> assert test_haar_dec(haar_dec)\nTest passed.\n","hidden":false,"locked":false},{"code":">>> assert test_haar_rec(haar_rec)\nTest passed.\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q3b":{"name":"q3b","points":10,"suites":[{"cases":[{"code":">>> np.random.seed(120)\n>>> signal = np.random.randn(30)\n>>> thresholded = threshold_coefficients(haar_dec(signal), 1)\n>>> assert np.allclose(thresholded[0], [1.30928796])\n>>> assert np.allclose(thresholded[1], [0])\n>>> assert np.allclose(thresholded[2], [-1.55465993, 0, 0])\n>>> assert np.allclose(thresholded[3], [0, 0, 1.25423218, 0, 2.24225713, 1.88273688, 0])\n>>> assert np.allclose(thresholded[4], [1.3275155641571719,1.9354719024998506,0.0,1.219712655652868,0.0,0.0,0.0,0.0,0.0,-1.9143112495030299,1.2362922101699199,0.0,0.0,0.0,0.0])\n","hidden":false,"locked":false},{"code":">>> np.random.seed(31415926)\n>>> signal = np.random.randn(50)\n>>> thresholded = threshold_coefficients(haar_dec(signal), 0.5)\n>>> assert np.allclose(thresholded[0], [-1.29768552254065])\n>>> assert np.allclose(thresholded[1], [-0.6647938745988833])\n>>> assert np.allclose(thresholded[2], [0.0,-1.2192668473377584,0.0])\n>>> assert np.allclose(thresholded[3], [-0.5543685062971575,0.0,1.7359956762918087,0.0,0.7356977385542033,-0.5215060486335091])\n>>> assert np.allclose(thresholded[4], [-0.9268256188606186,1.9467693278456002,-1.8643232839138064,0.0,-0.7011601829020109,2.0928318011273364,-0.534862197137459,-1.4345417530706088,0.9359701703066026,-0.5542631228902297,1.2852781579344579,-1.1084233980615386])\n>>> assert np.allclose(thresholded[5], [-1.6577738651265959,0.0,-1.812283167109967,0.0,0.0,0.7366944474117919,-2.0553989333690206,0.0,0.6886191111053033,0.0,1.2180232512249078,1.2501766444071016,-1.4683688171230327,0.0,0.0,0.0,-2.2667213362932337,0.6040176618248001,-0.5356331986152992,0.0,0.0,1.0007408588888809,0.0,0.0,1.591289047210473])\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]},"q3c2":{"name":"q3c2","points":5,"suites":[{"cases":[{"code":">>> blocks = plt.imread('data/blocks.tif')\n>>> assert np.allclose(blocks, deblurred_image, rtol=0.2, atol=50)\n","hidden":false,"locked":false}],"scored":true,"setup":"","teardown":"","type":"doctest"}]}}}},"nbformat":4,"nbformat_minor":4}